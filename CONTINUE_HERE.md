# Как продолжить работу в новом чате

## Шаг 1: Напиши мне

```
Продолжаем работу над проектом NEW-VOICE 2.0.
Это платформа для создания голосовых AI-ботов.
Покажи файл PROGRESS.md чтобы понять где остановились.
```

## Шаг 2: Покажи файлы

Используй #File или просто открой эти файлы:
1. `new-voice/PROGRESS.md`
2. `.kiro/specs/scenario-engine/tasks.md`

## Шаг 3: Скажи что делать

Например:
- "Создай Groq LLM провайдер"
- "Покажи что уже сделано"
- "Объясни текущий статус"

---

## Краткое описание проекта

**NEW-VOICE 2.0** — платформа для создания голосовых AI-ботов:
- Боты общаются естественно, как люди
- Входящие и исходящие звонки
- Клиент сам настраивает этапы диалога через конфиг
- LLM генерирует ответы (не шаблоны)

**Технологии:**
- Python 3.12
- Ollama (Llama/Qwen) — локальный LLM на сервере
- Deepgram (распознавание речи)
- Cartesia (синтез речи)
- LiveKit (голосовой стриминг)
- MTS Exolve (телефония)

**Сервер:** 77.233.212.58 (Ubuntu 24.04)
**GitHub:** https://github.com/khak1m/new-voice

---

## Текущий статус

**Scenario Engine готов на 95%!**
**LLM провайдер готов — нужно установить Ollama на сервер**

**Сделано:**
- Модели данных (models.py)
- Загрузчик конфигов (config_loader.py)
- StateMachine — переходы между этапами
- ContextManager — контекст звонка
- FieldExtractor — извлечение данных из речи
- LanguageDetector — определение языка ru/en
- OutcomeClassifier — классификация результатов
- ScenarioEngine — основной движок
- OllamaLLMProvider — провайдер для локального LLM
- Пример конфига для салона красоты

**Следующее:**
- Установить Ollama на сервер (см. docs/04_ollama_setup.md)
- Протестировать LLM
- Voice Pipeline (LiveKit интеграция)
